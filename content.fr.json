{"pages":[],"posts":[{"title":"Tests statistiques du Khi-2: indépendance et ajustement","text":"Les Tests d&apos;hypotèses Introduction Un test d&apos;hypotèse permet de décider une hypotèse à partir d&apos;une observation partielle. Ces tests permettent de vérifier si une série de données suit ou non une lois de probabilité ou l&apos;indépendance de deux variables aléatoires. On appelle \\(H_0\\) l&apos;hypotèse à vérifier &quot;par défaut&quot;, et \\(H_1(H_0\\) est fausse\\()\\). Pour cela on utilise le test du khi-deux \\(\\chi^2\\). Il existe plusieurs types de test, qui suivent une méthode communes: On compare : tableau observé avec le tableau théorique On calcule la distance \\(T\\) entre ces tableaux On calcule le degré de liberté \\(ddl\\) On trouve, à l&apos;aide de la table de \\(\\chi^2~(ddl,\\alpha=niveau~de ~liberté~en~\\%)\\), la valeur critique de la distance On rejette \\(H_0\\) si la distance est supérieure à la valeur critique Le test d&apos;ajustement Pour tester si une variable suit une loi donnée. Exemple: X (une v.a) suit/ne suit pas la loi L? On pose les alternative: \\(\\large H_0 = &quot;La~variable~X~suit~la~loi~L&quot;\\\\H_1 = &quot;La~variable~X~ne~suit~pas~la~loi~L&quot;\\) On calcule la distance du \\(\\chi^2\\) avec le tableaux observé et théorique: \\(T = \\displaystyle\\sum_{i=1}^k \\frac{(n_i-np_i)^2}{np_i} = \\sum\\frac{(eff~obs-eff~théo)^2}{eff~théo}\\) On calcule la zone de rejet (en trouvant la valeur critique \\(c\\) dans la table): \\(ddl = nb~classes - nb~paramètres - 1 \\\\\\alpha=niveau~de ~liberté~en~\\%\\) Si \\(T &gt; c\\), on rejette \\(H_0\\), sinon on accepte \\(H_0\\) Le test d&apos;indépendance Pour tester si des variables sont indépendantes. Exemple: X et Y (des va.) sont/ne sont pas indépendantes ? On pose les alternative: \\(H_0 = &quot;X~et~Y~sont~indépendantes&quot;\\\\ H_1 = &quot;X~et~Y~ne~sont~pas~indépendantes&quot;\\) On a le tableau suivant: \\(\\begin{array}{c|ccc:c} XY &amp; y_1 &amp; y_j&amp; y_r &amp; \\sum \\\\ \\hline x_1 &amp; n_{1,1} &amp; n_{1,j} &amp; n_{1,r} &amp; n_1. \\\\ x_k &amp; n_{k,1} &amp; \\textcolor{red}{n_{k,j}} &amp; n_{k,r} &amp; \\textcolor{blue}{n_k.}\\\\ x_q &amp; n_{q,1} &amp; n_{q,j} &amp; n_{q,r} &amp; n_q.\\\\ \\hdashline \\sum &amp; n._1 &amp; \\textcolor{green}{n._j} &amp; n._j &amp; \\bold{n.. = n} \\end{array}\\) On calcule la distance du \\(\\chi^2\\) avec le tableaux observé et théorique: \\(T = \\displaystyle\\sum_{k=1,...,q}\\sum_{j=1,...,r} \\frac{(\\textcolor{red}{n_{kj}}-n_{kj}(théo))^2}{n_{kj}(théo)} = \\sum_k\\sum_j\\frac{(eff~obs-eff~théo)^2}{eff~théo}\\\\~\\\\ avec~n_{k,j}(théo) = \\frac{\\textcolor{blue}{n_k.}\\textcolor{green}{n._j}}{n}\\) \\(\\large Exemple:~tableau~observée \\\\ \\begin{array}{c|cc:c} XY &amp; y_1 &amp; y_2 &amp; \\sum \\\\ \\hline x_1 &amp; 5 &amp; 10 &amp; 15 \\\\ x_2 &amp; 3 &amp; 10 &amp; 13\\\\ \\hdashline \\sum &amp; 8 &amp; 20 &amp; \\bold{n = 28} \\end{array} \\\\~\\\\ T = \\frac{(5-\\frac{15*8}{28})^2}{\\frac{15*8}{28}} +\\frac{(10-\\frac{15*20}{28})^2}{\\frac{15*20}{28}} +\\frac{(3-\\frac{13*8}{28})^2}{\\frac{13*8}{28}} +\\frac{(10-\\frac{13*20}{28})^2}{\\frac{13*20}{28}}\\) On calcule la zone de rejet (en trouvant la valeur critique \\(c\\) dans la table): \\(ddl = (q-1)(r-1) \\\\\\alpha=niveau~de ~liberté~en~\\%\\) Si \\(T &gt; c\\), on rejette \\(H_0\\), sinon on accepte \\(H_0\\) L&apos;implémentation en python On utilise scipy qui contient de nombreuses fonctions statistiques: import scipy.stats as stat Pour trouver une valeur dans la table avec le niveau de liberté \\(\\alpha\\) et le degré de liberté \\(ddl\\) on utilise la fonction chi2.ppf: ddl=10alpha = 5 / 100stat.chi2.ppf(1 - alpha,ddl) Implémentation du test d&apos;ajustement Un exemple d&apos;implémentation pour un test d&apos;ajustement sur une loi Binomiale \\(B(5,0.3)\\) On commence par générer un échantillon observé: #Pour générer les tableaux observésfrom numpy import *from random import *#B(N,p) avec N=5 et p=0.3N=5p=0.3#Nombre de tirage et tableau observén=10000X=binomial(N,p,n)Hobs=hist(X,range=(0,N+1),bins=N+1)effobs=Hobs[0] Puis on crée le tableau théorique: efftheo=zeros(N+1)for k in range(N+1): c=math.factorial(N)/(math.factorial(k)*math.factorial(N-k)) prob=c*(p**k)*(1-p)**(N-k) efftheo[k]=n*prob Pour comparer ces deux tableaux, on crée une fonction testAjust. qui prend en argument les deux tableaux théoriques et observés, ainsi que le niveau de liberté. Cette fonction renvoie un boolean avec true: rejet et false: accepté def testAjust(obs, theo, niv): distance = sum(((obs - theo) ** 2) / theo) ddl = len(obs) - 1 critic = stat.chi2.ppf(1 - niv,ddl) return distance &lt; critic On peux enfin obtenir un résultat à notre test directement: print(testAjust(effobs,efftheo,niv))","link":"/fr/Chi-squared-statistic-test/"}],"tags":[{"name":"Statistiques","slug":"Statistiques","link":"/fr/tags/Statistiques/"},{"name":"Probabilitées","slug":"Probabilitees","link":"/fr/tags/Probabilitees/"}],"categories":[{"name":"Maths","slug":"Maths","link":"/fr/categories/Maths/"}]}